{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27359663",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1><strong>Physics 129L: Classical (``Quantum'') Simulation (part2) </strong></h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b338722",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h2><strong> Heisenberg Hamiltonian </strong></h2>\n",
    "</div>\n",
    "\n",
    "The Heisenberg XXX Hamiltonian with the external $Z$ direction coupling,\n",
    "\n",
    "$$H = -J_{\\perp}\\sum_{\\langle ij \\rangle} \\left(X_iX_j + Y_iY_j\\right)  - J_Z Z_iZ_j + B\\sum_i Z_i, $$\n",
    "\n",
    "where $X,Y,Z$ are Pauli operators, $\\langle ij \\rangle$ sums nearest-neighbor (nn) sites. In the language of second quantization, the above Pauli operators can be expressed via the Jordan–Wigner transformation,\n",
    "\n",
    "$$H =\\sum_{i} \\left( -2J_Z(c^{+}_{i}c^{+}_{j}c_ic_j -c^{+}_{i}c_i)+B c^{+}_{i}c_i \\right)- J_{\\perp} \\sum_{\\langle ij \\rangle} \\left( c^{+}_{i}c_j \\right)$$\n",
    "\n",
    "where the fermionic anti-commutation relations,\n",
    "\n",
    "$$|{\\uparrow} \\rangle =|{1} \\rangle\\\\\n",
    "|{\\downarrow} \\rangle=|{0} \\rangle\\\\\n",
    "|{1} \\rangle_i=c^{+}_i |{0} \\rangle_i\\\\\n",
    "0=c^{+}_i |{1} \\rangle_i\\\\\n",
    "0=c_i |{0} \\rangle_i\\\\\n",
    "|{0} \\rangle_i=c_i |{1} \\rangle_i\\\\\n",
    "        \\{c_i,c_j\\}=\\delta_{ij},$$\n",
    "\n",
    "The Pauli $Z$ operator acts as the density operator for the system under this transformation. For a Heisenberg dimer, the above Hamiltonian is reduced to the form,\n",
    "\n",
    "$$H = -2J_Z(c^{+}_{1}c^{+}_{2}c_1c_2 -c^{+}_{1}c_1-c^{+}_{2}c_2  )+B\\left( c^{+}_{1}c_1+c^{+}_{2}c_2\\right) \n",
    "-J_{\\perp} \\left( c^{+}_{1}c_2+c^{+}_{2}c_1 \\right)$$\n",
    "\n",
    "For 2-spin system, the basis states are, $   |{00} \\rangle,|{10} \\rangle,|{01} \\rangle, |{11} \\rangle$, where the index location represents the sites (i.e. $1,2$). The Hamiltonian is given,\n",
    "\n",
    "$$H =\\begin{bmatrix}\n",
    "0 & 0 &0 &0\\\\\n",
    "0 & B+2J_{Z} &-J_{\\perp} &0\\\\\n",
    "0 & -J_{\\perp} & B+2J_{Z}  &0\\\\\n",
    "0 & 0 &0 & 2B+2J_{Z}\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "The result of the Jordan–Wigner transformation can be naturally translated into the 2-qubits. Let's use the first order Trotter–Suzuki expression, the time evolution can be expressed as,\n",
    "\n",
    "$$    e^{-i Ht}=\\left(\\prod _j^m e^{i H_j t/r}\\right)^r. $$\n",
    "\n",
    "We first focus on the simplest random Hamiltonian with total site $N$, in a block diagonal form, and each block contains numbers of spin up sites (i.e. number of i),\n",
    "$$  H= \\begin{bmatrix}\n",
    "    H_{0} &0 & 0 &...\\\\\n",
    "    0 &  H_{1} & 0 &...\\\\\n",
    "    0 & 0& H_{2} & ...\\\\\n",
    "    ... & ... & ... & ...\\\\\n",
    "    \\end{bmatrix}$$\n",
    "\n",
    "Since the Hamiltonian conserves the spins, each block-Hamiltonian (i.e. $H_{i}$) is hermitian and self-contained (no interaction between blocks), representing all states with n spin up sites. The dimension for each  block-Hamiltonian can be calculated,\n",
    "\n",
    "$$ \\mathcal{D}(H_{i})= {N \\choose{i} } \\times {N \\choose{i} },$$\n",
    "\n",
    "from the permutation arrangement. \n",
    "\n",
    "$$  H= \\begin{bmatrix}\n",
    "    0 &0 & 0 & 0 &0& 0& 0& ...\\\\\n",
    "    0 &  B & J_{12} &J& 0&0& 0&  ...\\\\\n",
    "    0 & J& B & J& 0&0& 0&  ...\\\\\n",
    "    0 & J & J& B &0& 0& 0&  ...\\\\\n",
    "    0 & 0 & 0 & 0& 2B & J&  J& J&...\\\\\n",
    "    0 & 0 & 0 & 0&  J&  2B & J&J& ...\\\\\n",
    "    0 & 0 & 0 & 0&  J&  J&2B & J&...\\\\\n",
    "    ... & ... & ... & ...& J & J& J&... \\\\\n",
    "    \\end{bmatrix}, $$\n",
    "    \n",
    "where $B$ is the z-direction external field, and $J_{lm}$ is the hopping term between site l and site m. We simulate a random interaction, where the hopping strength is sampled from a uniform distribution i.e. $ J_{lm}=J_{ml} \\in U(0,J)$, where $J$ is the maximum interaction strength. Although the nearest neighbor interaction does not obey a traditional geometric metric, this heisenberg model provides a minimal example to study stochastic sampling. One special case of the above system is given by the homogeneous N-neighbor heisenberg model above ($J_z=0$). We limit our eigen-values to be non-negative, and it translate into the condition $B\\ge J>0$. For small system size, the above Hamiltonian can be exactly diagonalized. We then rescale the Hamiltonian by its largest eigen-value $\\lambda_{max}$ to ensure $\\lambda_i \\in [0,1]$. \n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <h2><strong> Maximally distributed State </strong></h2>\n",
    "</div>\n",
    "The superposition of states is given,\n",
    "$$  |{AB} \\rangle=\\frac{1}{\\sqrt{2^N}}\\sum_j |{\\lambda_i}\\rangle, $$\n",
    "where the $|{AB}\\rangle$ state is the maximally distributed state, and $|{\\lambda_i}\\rangle$ are the eigenstates of the Hamiltonian. The time evolution operator is given, \n",
    "\n",
    "$$    e^{-i Ht}=\\left(e^{-i H t/n}\\right)^n  \\approx \\left(\\mathcal{I}-i\\hat H \\delta t\\right)^n ,$$\n",
    "\n",
    "and the evolution of the maximally distributed state $ |{AB} \\rangle $ is,\n",
    "\n",
    "$$      e^{-i Ht} |{AB}\\rangle=\\frac{1}{\\sqrt{2^N}} \\sum_j e^{-i \\lambda_j t} |{\\lambda_j}\\rangle .$$\n",
    "\n",
    "The time evolution coefficient and its spectrum can be calculated,\n",
    "\n",
    "$$      c_{AB}(t)=\\langle{AB}| e^{-i Ht} |{AB}\\rangle=\\sum_j \\sum_k  e^{-i \\lambda_j t} \\delta_{jk}=\\sum_j  e^{-i \\lambda_j t}=\\mathcal{F}^{-1}\\left(\\sum_j \\delta(\\omega-\\lambda_j)\\right),$$\n",
    "\n",
    "where we use the orthonormal condition in the second equality. This condition can be automatically meet as the Hamiltonian is real and hermitian. The reference evolution coefficient and power spectrum can be directly calculated from the expression, using exact diagnaization, \n",
    "\n",
    "$$c_{AB}(t)=\\sum_j \\frac{1}{\\sqrt{2^N}}  e^{-i \\lambda_j t}=\\mathcal{F}^{-1}\\left(\\frac{1}{\\sqrt{2^N}} \\sum_j \\delta(\\omega-\\lambda_j)\\right).$$\n",
    "\n",
    "\n",
    "We expect the power spectrum as delta functions that recovers the degeneracy information, and the discrepancy comes from the Scipy.FFT module. We compare this result by first propagating the individual eigen-vectors and average their power spectrum. This state $|{BA}\\rangle$ is given,\n",
    "\n",
    "$$     c_{BA}(t)= \\mathcal{F}^{-1}\\left( \\frac{1}{\\sqrt{2^N}}\\sum_j \\mathcal{F} (\\langle{\\lambda_j}|e^{-i Ht} |{\\lambda_j}\\rangle) \\right).$$\n",
    "\n",
    "\n",
    "\n",
    "In general, maximally distributed state requires full information on eigen-states (e.g. by ED), and the computational cost increases exponentially with system size. Alternatively, we can sample the Hilbert space stochastically. By time evolving each random state, we can recover partial information about the spectrum. The statically average of those spectrum should asymptotically convergence to a spectrum that reflects both eigen-values information and degeneracies. \n",
    "A general state can be expressed as the sum of complete eigen-basis of the Hamiltonian. \n",
    "\n",
    "$$    |{\\zeta_s}\\rangle = \\frac{1}{\\sqrt{2^N}}\\sum_{j=1}^N c_j |{\\lambda_j}\\rangle,$$\n",
    "\n",
    "where $ |{\\lambda_j}\\rangle$ is an eigen-state of the Hamiltonian, and $c_j \\equiv e^{i\\theta_j}$. $\\theta\\in[0,2\\pi]$ is a random number sampled from a uniform distribution. The random vector is time-evolved as:\n",
    "\n",
    "$$    |{\\zeta(t)_s}\\rangle= e^{i\\hat H t} |{\\zeta_s}\\rangle=\\left(e^{i\\hat H \\delta t}\\right)^n |{\\zeta_s}\\rangle \\approx \\left(\\mathcal{I}-i\\hat H \\delta t\\right)^n |{\\zeta_s}\\rangle.$$\n",
    "\n",
    "The evolution coefficient of a random vector is,\n",
    "\n",
    "$$   {c}_s(t) = \\langle{\\zeta(t)_s|\\zeta_s}\\rangle.$$\n",
    "\n",
    "The power spectrum is given by the Fourier transform,\n",
    "\n",
    "$$     {c}_s(\\omega) =\\mathcal{F} (\\tilde{c}_s(t) ),$$\n",
    "\n",
    "Averaging the power spectrum with sample size S, \n",
    "\n",
    "$$    \\bar{c}_S(\\omega)=\\frac{1}{S}\\sum_s  {c}_s(\\omega),$$\n",
    "\n",
    "and this expression should asymptotically convergence to the true power spectrum,\n",
    "\n",
    "$$    \\lim_{S\\to \\infty} \\bar{c}_S(\\omega) =\\left(\\frac{1}{\\sqrt{2^N}} \\sum_j \\delta(\\omega-\\lambda_j)\\right) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a5ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import factorial\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from numpy.linalg import matrix_power\n",
    "import scipy.fft as fft\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "#import seaborn as sns\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import math\n",
    "from scipy.linalg import block_diag\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks\n",
    "import json\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "path_this_script = os.path.realpath(sys.argv[0])\n",
    "path_this_script_splitted = os.path.split(path_this_script)[0]\n",
    " \n",
    " \n",
    "class Gene:\n",
    "    # Class def \n",
    "    def __init__(self,T,dt,sample_size):\n",
    "\n",
    "        self.T=T # total time evolution\n",
    "        self.dt=dt\n",
    "        self.N_t=int(T/dt)\n",
    "        self.sample_size=sample_size\n",
    "    def set_H(self,H):\n",
    "        self.H=H\n",
    "    def set_parent_dir(self,parent_path,rebuid=True): # Important for setting home dir\n",
    "        if rebuid: # if exsits, remove and build.\n",
    "            try:\n",
    "                os.mkdir(parent_path)\n",
    "                os.mkdir(parent_path+'/img')\n",
    "                os.mkdir(parent_path+'/img_max_state')\n",
    "                #os.mkdir(parent_path+'/data')\n",
    "                os.mkdir(parent_path+'/stochastic')\n",
    "                os.mkdir(parent_path+'/reference')\n",
    "                os.mkdir(parent_path+'/stochastic_peak')\n",
    "                os.mkdir(parent_path+'/reference_peak')\n",
    "                os.mkdir(parent_path+'/peak_std')\n",
    "\n",
    "            except:\n",
    "                shutil.rmtree(parent_path)\n",
    "                os.mkdir(parent_path)\n",
    "                os.mkdir(parent_path+'/img')\n",
    "                os.mkdir(parent_path+'/img_max_state')\n",
    "                os.mkdir(parent_path+'/stochastic')\n",
    "                os.mkdir(parent_path+'/reference')\n",
    "                os.mkdir(parent_path+'/stochastic_peak')\n",
    "                os.mkdir(parent_path+'/reference_peak')\n",
    "                os.mkdir(parent_path+'/peak_std')\n",
    "        self.parent_dir=parent_path\n",
    "        self.img_dir=parent_path+'/img'\n",
    "        self.img_dir_max=parent_path+'/img_max_state'\n",
    "        self.data_dir_random=parent_path+'/stochastic'\n",
    "        self.data_dir_reference=parent_path+'/reference'\n",
    "        self.data_dir_random_peak=parent_path+'/stochastic_peak'\n",
    "        self.data_dir_reference_peak=parent_path+'/reference_peak'\n",
    "        self.peak_std=parent_path+'/peak_std'\n",
    "        \n",
    "    def vec_gen(self,vec_length):\n",
    "        # generate a normalized vector\n",
    "        num_rand=2*np.pi*np.random.rand(vec_length)\n",
    "        vec=np.exp(1j*num_rand)\n",
    "       # vec=np.array([0,1,-1,0])\n",
    "        vec=vec/np.sqrt(np.sum(vec.real**2+vec.imag**2))   \n",
    "        return vec\n",
    "\n",
    "\n",
    "    def U_step(self):\n",
    "        # Trotter Expansion step\n",
    "        U_=np.eye(len(self.H))*(1+0*1j)-1j*self.H*self.dt#-0.001*H*delta_t\n",
    "        return U_\n",
    "         \n",
    "\n",
    "    def over_lap(self,U_,vin,vstart):\n",
    "        # Find evolution and overlap over a given unitary operator \n",
    "        vec_aft=U_@vin\n",
    "        vec_aft=vec_aft/np.sqrt(np.sum(vec_aft.real**2+vec_aft.imag**2))\n",
    "        return vec_aft, np.inner(np.conjugate(vec_aft),vstart)\n",
    "\n",
    "    def fft_(self,arry):\n",
    "        # perform DFT for a given array\n",
    "        arry_f = fft.fft(arry)/(self.N_t)\n",
    "        freq_=fft.fftfreq(self.N_t,self.dt) \n",
    "        # fftshift: the result is typically an array where the zero-frequency component is located at the top-left corner\n",
    "        arry_f = fft.fftshift(arry_f)\n",
    "        freq_ = fft.fftshift(freq_)\n",
    " \n",
    "        return 2*np.pi*freq_, arry_f\n",
    "\n",
    "    def log_sampling(self,start=1, stop=2,num=50):\n",
    "        self.spacing_arry=np.logspace(start=start, stop=stop,num=num).astype(int)\n",
    "        print('Arry')\n",
    "        print(self.spacing_arry)\n",
    "    def linear_sampling(self,start=1, stop=100,num=50):\n",
    "        self.spacing_arry=np.linspace(start=start, stop=stop,num=num).astype(int)\n",
    "        print('Arry')\n",
    "        print(self.spacing_arry)\n",
    " \n",
    "\n",
    "    def time_propagate_fft(self,vec_0):\n",
    "        # fft over a given array, evolved under a unitary operator. \n",
    "        vec_overlap_arry=np.zeros(self.N_t)*1j\n",
    "        vec=vec_0\n",
    "        for j in range(0,self.N_t):\n",
    "            U_=self.U_step()\n",
    "            vec,vec_overlap_arry[j]=self.over_lap(U_=U_,vin=vec,vstart=vec_0)\n",
    " \n",
    "        fft_system=self.fft_( arry=vec_overlap_arry)\n",
    "        return np.abs(fft_system[1])/self.sample_size, fft_system[0].real, vec_overlap_arry\n",
    "    def fft_sum(self,fft_val,sample_index=1):\n",
    "        # assign values to DFT results \n",
    "        self.fft_result_std=self.sample_size*np.sqrt(np.abs(0.25*(self.fft_result/(sample_index+1)+fft_val)**2-(self.fft_result/(sample_index+1))**2))\n",
    "        self.fft_result=self.fft_result+fft_val\n",
    " \n",
    "    def unit2normal(self,unit_val,sample_index=1):\n",
    "        # average sample size\n",
    "        return unit_val*self.sample_size/(sample_index+1)\n",
    "\n",
    "    def peaks_result(self,num_max_val,sample_index=1):\n",
    "        # locate max peak of the DFT\n",
    "        res=self.unit2normal(self.fft_result,sample_index=sample_index)\n",
    "        # [::-1]: This part reverses the order of the sliced array. \n",
    "        # [-num_max_val:]: This part is slicing the array from the last num_max_val elements to the end. \n",
    "        max_vals_arg=np.abs(res).argsort()[-num_max_val:][::-1]\n",
    "        self.max_vals=np.abs(res[max_vals_arg])\n",
    "        self.max_vals_energy=np.abs(self.freq_[max_vals_arg])\n",
    "        self.max_vals_std=np.abs(res[max_vals_arg])\n",
    " \n",
    "\n",
    "    def ideal_spec(self,t_shifts=0):\n",
    "        # generate ideal spectral profile. \n",
    "        t_val=np.linspace(0,self.T,self.N_t)+t_shifts\n",
    "        exp_val=np.zeros(self.N_t)*1j\n",
    "        for s in range(0,len(self.order_eigen_val_2e)):\n",
    "            current_eigen=self.order_eigen_val_2e[s]\n",
    "            current_exp=np.exp(1j*current_eigen*t_val)\n",
    "            exp_val=exp_val+current_exp\n",
    "        \n",
    "        freq,exp_val_freq=self.fft_(exp_val)\n",
    "\n",
    "        return t_val,exp_val,exp_val_freq,freq\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    def ev(self,scale_factor=1,normal=True,frq=[],y_true=[],time=[],y_true_time=[]):\n",
    "        # time evolution \n",
    "       \n",
    "        self.index_=0\n",
    " \n",
    "        vec_length=len(self.H)\n",
    "        self.peak_data_arry=[]\n",
    " \n",
    "        self.fft_result=0*1j\n",
    "        self.fft_result_std=0*1j\n",
    "        current_vec_overlap_arry=np.zeros(self.N_t)*1j\n",
    "        for i in range(0,self.sample_size):\n",
    "\n",
    "            vec_0=self.vec_gen(vec_length)\n",
    "            print('Data Dir: '+self.parent_dir)\n",
    "            print('Index: '+str(i)+'/'+str(self.spacing_arry[self.index_]))\n",
    "            unit_fft_val,self.freq_,vec_overlap_arry=self.time_propagate_fft(vec_0)\n",
    "            self.fft_sum(fft_val=unit_fft_val,sample_index=i) \n",
    "\n",
    "            self.peaks_result(num_max_val=4)\n",
    "            current_vec_overlap_arry=(current_vec_overlap_arry+vec_overlap_arry)\n",
    "\n",
    "            if (i ==self.spacing_arry[self.index_]) :\n",
    "          \n",
    "                \n",
    "                self.plot_time_domain((current_vec_overlap_arry-np.mean(current_vec_overlap_arry))/i,N=self.N_t,T=self.T,out_loc=self.img_dir +'/'+str(self.index_)+'_t'+'.png',time=time,y_true_time=y_true_time )    \n",
    "                self.plot(out_loc=self.img_dir +'/'+str(self.index_)+'.png',scale_factor=scale_factor,normal=normal,sample_index=i,frq=frq,y_true=y_true)\n",
    "                self.get_peak_val(save_val=True,name='',loc=self.data_dir_random_peak)\n",
    "                self.save_fft_data(name='',scale_factor=scale_factor,normal=normal,sample_index=i,loc=self.data_dir_random)\n",
    "                self.sample_out(self.index_)\n",
    "                \n",
    "                self.index_=self.index_+1\n",
    "\n",
    "\n",
    "    \n",
    "    def ev_max_state(self,scale_factor=1,normal=True):\n",
    "       # time evolution of an alternative def\n",
    "       \n",
    "        self.index_=0\n",
    "      #  dt=T/N_t\n",
    "        eig_length=len(self.order_eigen_val_2e)\n",
    "        self.peak_data_arry=[]\n",
    "        self.fft_result=0*1j\n",
    "\n",
    " \n",
    "        for i in range(0,eig_length):\n",
    "            vec_0=self.max_state(index=i)\n",
    "            print('Index: '+str(i))\n",
    "            unit_fft_val,self.freq_,vec_overlap_arry=self.time_propagate_fft(vec_0)\n",
    "            self.fft_sum(fft_val=unit_fft_val,sample_index=0) \n",
    "            self.peaks_result(num_max_val=eig_length)\n",
    "        \n",
    "        self.plot(out_loc=self.img_dir_max +'/individual_propagate.png',scale_factor=scale_factor,normal=normal,sample_index=0,fill_=False)\n",
    "        self.get_peak_val(save_val=True,name='individual_propagate',max_state=True,loc=self.data_dir_reference_peak )\n",
    "        self.save_fft_data(name='individual_propagate',scale_factor=scale_factor,normal=normal,sample_index=0,loc=self.data_dir_reference )\n",
    "        vec_0=self.max_mix_state()\n",
    "        unit_fft_val,self.freq_,vec_overlap_arry=self.time_propagate_fft(vec_0)\n",
    "        self.fft_result=unit_fft_val\n",
    "        \n",
    "        self.plot_time_domain(vec_overlap_arry-np.mean(vec_overlap_arry),N=self.N_t,T=self.T,out_loc=self.img_dir +'/'+'direct_propagate_t'+'.png')    \n",
    "\n",
    "        self.plot(out_loc=self.img_dir_max +'/direct_propagate.png',scale_factor=scale_factor,normal=normal,sample_index=0,fill_=False)\n",
    "        self.get_peak_val(save_val=True,name='direct_propagate',max_state=True,loc=self.data_dir_reference_peak)\n",
    "        self.save_fft_data(name='direct_propagate',scale_factor=scale_factor,normal=normal,sample_index=0,loc=self.data_dir_reference )\n",
    "\n",
    "    def scale_sort(self,scale_factor=1,normal=True,sample_index=1):\n",
    "        # sort the DFT result and frequency with an overall factor.  \n",
    "        sort_freq=np.argsort(self.freq_)\n",
    "        freq_=self.freq_[sort_freq]/scale_factor\n",
    "        self.mag=np.abs(self.fft_result)[sort_freq]\n",
    "        self.mag=self.unit2normal(unit_val=self.mag,sample_index=sample_index)\n",
    "        self.mag_std=np.abs(self.fft_result_std)[sort_freq] \n",
    " \n",
    "        if normal:\n",
    "            self.mag=self.mag/self.mag[freq_==0]\n",
    "            self.mag_std=np.abs(self.fft_result_std)[sort_freq]/self.mag[freq_==0]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        peaks = find_peaks(self.mag, height = 0.2, threshold = 0.1, distance = 2)\n",
    "        self.height = peaks[1]['peak_heights'] #list of the heights of the peaks\n",
    "        self.peak_pos =freq_[peaks[0]] #list of the peaks positions\n",
    "        self.peak_std=self.mag_std[peaks[0]]\n",
    "\n",
    "\n",
    "        return freq_\n",
    "         \n",
    "    def cut_freq_arry(self,freq_,value):\n",
    "        # give a frequency cut-off\n",
    "        new_freq_index=abs(freq_)<value\n",
    "        return self.mag[new_freq_index], self.mag_std[new_freq_index],freq_[new_freq_index]\n",
    "\n",
    "    def save_fft_data(self,name='data',scale_factor=1,normal=True,sample_index=1,loc='/'):\n",
    "        # export the DFT out to a csv file \n",
    "        freq_=self.scale_sort(scale_factor=scale_factor,normal=normal,sample_index=sample_index)\n",
    "        mag,mag_std,freq_=self.cut_freq_arry(freq_,value=1.5)\n",
    "        arry=np.vstack((freq_,mag))\n",
    "        arry=np.vstack((arry,mag_std))\n",
    " \n",
    "        self.save(array=arry,append_=True,data_file=loc+'/'+name+str(sample_index)+'.csv')\n",
    "    \n",
    "    def diag(self):\n",
    "        # calculate eigenvalues and the scale factor \n",
    "        V=linalg.eig(self.H)\n",
    "        inde_arry=np.argsort(V[0])\n",
    "        self.order_eigen_vec_2e=np.round((V[1].T[inde_arry]),15)\n",
    "        scale_factor=(np.round((V[0][inde_arry]),15)).max()/3 # the Mag for B field\n",
    "        self.scale_factor=scale_factor\n",
    "        self.order_eigen_val_2e=np.round((V[0][inde_arry]),15)/scale_factor\n",
    "        self.eigen_size=len(self.order_eigen_val_2e)\n",
    "        self.unique_eigen_val_2e, self.eigen_degen_2e = np.unique(np.round(self.order_eigen_val_2e,5), return_counts=True)\n",
    "\n",
    "\n",
    "        return scale_factor\n",
    "\n",
    "    def sample_out(self,index):\n",
    "        \n",
    "        self.save(array=np.array([self.spacing_arry[index]]),append_=True,data_file=self.parent_dir+'/sample_arry.csv')\n",
    "    def max_state(self,index):\n",
    "        state_mx=self.order_eigen_vec_2e[index]\n",
    "        return state_mx\n",
    "    def max_mix_state(self):\n",
    "        # calculate max mix state \n",
    "        state_mx=0\n",
    "        for i in range(0,len(self.order_eigen_vec_2e)):\n",
    "            state_mx=state_mx+self.order_eigen_vec_2e[i]\n",
    "         \n",
    "        return state_mx\n",
    " \n",
    "\n",
    "    def save(self,array,append_=True,data_file='peak_data.csv'):\n",
    "        # output file\n",
    "        if append_:\n",
    "            with open(data_file, \"a\") as f:\n",
    "                np.savetxt(f, np.column_stack(array.real), fmt='%f', delimiter=',')\n",
    "        else:\n",
    "            with open(data_file, \"w+\") as f:\n",
    "                np.savetxt(f, np.column_stack(array.real), fmt='%f', delimiter=',')\n",
    "\n",
    "    def plot_time_domain(self, arry,N,T,out_loc='data.png',time=[],y_true_time=[],lw=1):\n",
    "        plt.figure(figsize=(4, 1.5))\n",
    "        t=np.linspace(0,T,N)*self.scale_factor \n",
    "\n",
    "        plt.plot(t,arry,alpha=1,c='seagreen',label='sample',lw=0.5)\n",
    "\n",
    "        x_range=[0,6]\n",
    "        plt.xlim([x_range[0], x_range[1]])\n",
    "        plt.ylim([-1.2, 1.2])\n",
    "        s='dt: '+str(np.round(T/N,10))\n",
    "        plt.title(s, fontsize=10)\n",
    "\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.savefig(out_loc, dpi=400, format=\"png\")\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_peak_val(self,save_val=False,name='max_state',max_state=False,loc='/'): \n",
    "        if max_state:\n",
    "            arry=np.vstack((self.height[np.argsort(self.peak_pos)],self.peak_std[np.argsort(self.peak_pos)]))\n",
    "            arry=np.vstack((arry,self.peak_pos[np.argsort(self.peak_pos)]))\n",
    "        else:\n",
    "            arry=np.vstack((self.height[np.argsort(self.peak_pos)],self.peak_std[np.argsort(self.peak_pos)]))\n",
    "            arry=np.vstack((arry,self.peak_pos[np.argsort(self.peak_pos)]))\n",
    "        if save_val:\n",
    "            self.save(array=arry,append_=True,data_file=loc+'/'+name+'_peak.csv')\n",
    "\n",
    "\n",
    "    def plot(self,out_loc='data.png',scale_factor=1,normal=False,sample_index=1,fill_=False,frq=[],y_true=[]):\n",
    "        plt.figure(figsize=(4, 1.5))\n",
    "        freq_=self.scale_sort(scale_factor=scale_factor,normal=normal,sample_index=sample_index)\n",
    "        ax=plt.plot(freq_,self.mag/np.max(self.mag),alpha=1,label=str(sample_index+1),color='seagreen',lw=0.5)\n",
    "        plt.scatter(freq_,self.mag/np.max(self.mag),alpha=0.4,s=5.5,color='seagreen',zorder=3)\n",
    "\n",
    "        if fill_:\n",
    "            plt.fill_between(freq_, self.mag - self.mag_std, self.mag + self.mag_std, color='green', alpha=0.2, lw=6)\n",
    "    \n",
    "        for i in range(0,len(self.order_eigen_val_2e)):\n",
    "            plt.axvline(x=self.order_eigen_val_2e[i], ymin=0, ymax=1, c='black', ls='--', lw=0.8,alpha=1)\n",
    "        plt.grid()\n",
    "        x_range=[-1.5*(np.abs(self.order_eigen_val_2e).max()),1.5*(np.abs(self.order_eigen_val_2e).max())]\n",
    "        plt.xlim([x_range[0], x_range[1]])\n",
    "\n",
    "        s='Ideal Eigen-Value Peaks'+np.array2string(self.eigen_degen_2e, precision=2, separator=',',suppress_small=True)+'\\n Sample Size: '+str(sample_index+1)+'(dt: '+str(np.round(self.dt*1000,2))+'e-3)'+r'(d$\\omega$: '+str(np.round((1/scale_factor*2*np.pi/self.T)*1000,2))+'e-3)'\n",
    "\n",
    "        plt.title(s, fontsize=10)\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "        plt.savefig(out_loc, dpi=400, format=\"png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def simple_plot(self,freq_,y,out_loc='data.png',scale_factor=1,label_name=[''],frq=[],y_true=[]):\n",
    "        plt.figure(figsize=(4, 1.5))\n",
    "\n",
    "\n",
    "        for i in range(0,len(y)):\n",
    "            \n",
    "            current_y=y[i]\n",
    " \n",
    "            if i==0:\n",
    " \n",
    "\n",
    "\n",
    "                plt.scatter([-3,-1,1,3],[1,1,1,1],alpha=1,s=0.5,color='black',zorder=3,marker='s')\n",
    "            else:\n",
    "                ax=plt.plot(freq_,current_y,alpha=1,label=label_name[i],color='tab:blue',lw=0.5)\n",
    "                plt.scatter(freq_,current_y,alpha=0.2,s=5.5,color='tab:blue',zorder=3,marker='s')\n",
    "\n",
    "                for j in range(0,len(self.order_eigen_val_2e)):\n",
    "                    plt.axvline(x=self.order_eigen_val_2e[j], ymin=0.05, ymax=0.95, c='black', ls='--', lw=0.8,alpha=1)\n",
    "                plt.grid()\n",
    "                x_range=[-1.5*(np.abs(self.order_eigen_val_2e).max()),1.5*(np.abs(self.order_eigen_val_2e).max())]\n",
    "                plt.xlim([x_range[0], x_range[1]])\n",
    " \n",
    "                s='Eigen-Value Peaks' \n",
    "                plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "                plt.title(s, fontsize=10)\n",
    "                plt.xlabel('Normalized Energy')\n",
    "                plt.savefig(self.img_dir+out_loc, dpi=400, format=\"png\")\n",
    "        plt.close()\n",
    "\n",
    "    def plot_time_domain_simple(self, t,arry,out_loc='/data.png',label_name=[],lw=1):\n",
    "        plt.figure(figsize=(4, 1.5))\n",
    "        plt.scatter(t[0],arry[0],alpha=0.2,s=5.5,marker='s',color='tab:blue')\n",
    "        det_t=t[-1]\n",
    "        time_max=det_t.max() \n",
    "\n",
    "        full_arry_list=[]\n",
    "        full_arry_list_fft=[]\n",
    "        for i in range(0,len(t)):\n",
    "            if i!=int(len(t)-1):\n",
    "                current_arry=arry[i]\n",
    "                current_t=t[i]\n",
    "                repeated_time=current_t\n",
    "                repeated_arr=current_arry\n",
    "                for s in range(0,int(np.ceil(time_max/current_t.max()))-1):\n",
    "                    new_time=current_t+current_t.max()*(s+1)+0.3*(s+1)\n",
    "                    repeated_time= np.concatenate([repeated_time,new_time ])\n",
    "                    repeated_arr= np.concatenate([repeated_arr,current_arry ])\n",
    "                    \n",
    "                 \n",
    "                f = interp1d(repeated_time,repeated_arr, kind='quadratic',bounds_error=False) \n",
    " \n",
    "                full_arry_list.append(f(det_t))\n",
    "\n",
    "                plt.plot(det_t,f(det_t),alpha=1,label=label_name[i],lw=0.5)\n",
    "\n",
    "\n",
    "                freq_,val=self.fft_(f(det_t))\n",
    "                full_arry_list_fft.append(val)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                plt.plot(t[i],arry[i],alpha=1,label=label_name[i],color='black',lw=1,ls='--',zorder=1)\n",
    "            \n",
    "         \n",
    "\n",
    "        s='Time Domain: IBM Lagos, J/B=1' \n",
    "        plt.grid()\n",
    "        x_range=[0,6]\n",
    "        plt.xlim([x_range[0], x_range[1]])\n",
    "        plt.ylim([-1.2, 1.2])\n",
    "        plt.title(s, fontsize=10)\n",
    "        plt.legend()\n",
    "        plt.xlabel('time')\n",
    "        \n",
    "        plt.savefig(self.img_dir+out_loc, dpi=400, format=\"png\")\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "        arry=np.vstack((freq_,full_arry_list))\n",
    "        mag,mag_std,freq_=self.cut_freq_arry(freq_,value=1.5)\n",
    "        self.save(array=arry,append_=True,data_file='simple_time.csv')\n",
    "\n",
    "        return det_t, freq_, full_arry_list,full_arry_list_fft\n",
    "\n",
    "    def import_json(self,file_name='ibm_lagos_MaximallyMixed_CORRECTED_x_1.0_qubits[2, 1, 3]_XYZ.json'):\n",
    "        with open(file_name) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Extract the numerical values into a NumPy array\n",
    "        array_t=np.array(data[\"t\"])-data[\"t\"][0]\n",
    "        array_avg_x=np.array(data[\"avg_x\"])\n",
    "        array_avg_y=np.array(data[\"avg_y\"])\n",
    "        array_x00=0 \n",
    "        array_y00=0 \n",
    " \n",
    "        return array_t, array_x00, array_y00,array_avg_x,array_avg_y\n",
    "\n",
    "    def data_fft(self,arry=[]):\n",
    "        for i in range(0,len(arry)):\n",
    "            freq_, arry_f=self.fft_(arry=arry[i])\n",
    "\n",
    "\n",
    "    def videos(self,img_loc,out_loc,out_file_name,N=100):\n",
    "        img_array=[]\n",
    "        for i in range(0,N):\n",
    "            fig_loc=img_loc+'/'+str(i)+'.png'\n",
    "            print(fig_loc)\n",
    "            img = cv2.imread(fig_loc)\n",
    "            print(img.shape)\n",
    "            height, width, layers = img.shape\n",
    "            size = (width,height)\n",
    "            img_array.append(img)\n",
    " \n",
    "\n",
    "        out = cv2.VideoWriter(out_loc+out_file_name,cv2.VideoWriter_fourcc(*'DIVX'), 10, size)\n",
    "\n",
    "        for i in range(len(img_array)):\n",
    "            out.write(img_array[i])\n",
    "        out.release()\n",
    "                \n",
    "    def fft_test(self,theta,T,N_t,out_loc='data_test.png'):\n",
    "        f=theta\n",
    " \n",
    "        t_=np.linspace(0,T,N_t)\n",
    " \n",
    "        vec=np.exp(1j*2*np.pi*f*t_) \n",
    "\n",
    "        arry_f = fft.fft(vec)/N_t\n",
    "        freq_=fft.fftfreq(N_t,t_[1]-t_[0])\n",
    "        arry_f = fft.fftshift(arry_f)\n",
    "        freq_ = fft.fftshift(freq_)\n",
    "\n",
    "        plt.plot(freq_,np.abs(arry_f),alpha=0.5)\n",
    "        plt.grid()\n",
    "        plt.savefig(out_loc, dpi=200)\n",
    "        \n",
    "        return freq_,arry_f\n",
    "\n",
    "def Spin_chain_H_construct(net_sites,B,J):\n",
    "    size_arry=np.zeros(net_sites+1)\n",
    "    for i in range(0,net_sites+1):\n",
    "        size_arry[i]=math.comb(net_sites, i)\n",
    "\n",
    "    block_arry=[]\n",
    "    for k in range(0,len(size_arry)):\n",
    "        current_size=int(size_arry[k])\n",
    "        J_matrix=J*np.random.rand(current_size,current_size)*(np.ones((current_size,current_size))-np.eye(current_size))\n",
    "        current_blocks=B*k*np.eye(current_size)-0.5*J_matrix-0.5*J_matrix.T\n",
    "\n",
    "        block_arry.append(current_blocks)\n",
    "\n",
    "    H_matrix=block_diag(*block_arry)\n",
    "    return H_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a080e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    " \n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "\n",
    "\n",
    "\n",
    "B=1\n",
    "J=B*1\n",
    "  \n",
    "\n",
    "H2=-np.array([\n",
    "        [J+2*B,0,0,0],\n",
    "        [0,-J,2*J,0],\n",
    "        [0,2*J,-J,0],\n",
    "        [0,0,0,J-2*B]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_max_val=1\n",
    "T=100\n",
    "sample_size=100\n",
    "dt=0.0005 \n",
    "\n",
    "H_size=2**num_max_val\n",
    "export_sample_size=30\n",
    "\n",
    "H2=Spin_chain_H_construct(net_sites=H_size,B=B,J=J)\n",
    "print(H2.shape)\n",
    " \n",
    "type_mat='set' \n",
    "parent_path='example'\n",
    "\n",
    "max_energy=B*num_max_val\n",
    "H=H2\n",
    "G=Gene(T=T,dt=dt,sample_size=sample_size)\n",
    "G.set_parent_dir(parent_path=parent_path,rebuid=True)\n",
    "G.set_H(H=H)\n",
    "scale_factor=G.diag()\n",
    " \n",
    "\n",
    "array_t, array_x00, array_y00,array_avg_x,array_avg_y=G.import_json(file_name=current_directory+'/ibm_lagos_MaximallyMixed_CORRECTED_x_1.0_qubits[2, 1, 3]_XYZ.json')\n",
    " \n",
    "\n",
    "G.ev_max_state(scale_factor=scale_factor,normal=True)\n",
    "t_val,exp_val,exp_val_freq,freq=G.ideal_spec(t_shifts=0)\n",
    "det_t, freq_, full_arry_list,full_arry_list_fft=G.plot_time_domain_simple(out_loc='/data.png',t=[array_t,t_val],arry=[4*array_avg_y,0.25*(exp_val-np.mean(exp_val))],label_name=['<Y>','Exact']) #0.5*(exp_val-np.mean(exp_val))\n",
    "\n",
    "\n",
    "G.simple_plot(freq_=freq,y=[np.abs(exp_val_freq)],out_loc='/data_fft.png',scale_factor=scale_factor,label_name=['Exact'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#G.log_sampling(start=1, stop=4,num=export_sample_size)\n",
    "G.linear_sampling(start=1, stop=100,num=export_sample_size)\n",
    "\n",
    "G.ev(scale_factor=scale_factor,normal=True,frq=freq_,y_true=np.abs(exp_val_freq)/np.max(np.abs(exp_val_freq)),time=t_val,y_true_time=0.25*(exp_val-np.mean(exp_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba2ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908c1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
